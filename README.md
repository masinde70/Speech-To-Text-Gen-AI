
# Speech-To-Text-Gen-AI

A **Retrieval Augmented Generation (RAG)** system for audio data, powered by LangChain, Chroma, Hugging Face embeddings, AssemblyAI, and OpenAI's GPT models.

This project demonstrates how to transcribe audio files, embed their contents, and enable powerful question-answering over the audio using modern LLMs.

---

## Features

- **Automatic Transcription:** Downloads and transcribes audio from URLs using AssemblyAI.
- **Document Chunking:** Splits transcripts into manageable text chunks for efficient embedding and retrieval.
- **Embeddings:** Uses Hugging Face's `sentence-transformers/all-mpnet-base-v2` for high-quality text embeddings.
- **Vector Storage:** Stores embeddings in a Chroma vector database for fast similarity search.
- **Conversational QA:** Integrates OpenAI's GPT-3.5-turbo via LangChain for answering questions about the audio content, with source attribution.
- **Interactive CLI:** Simple terminal interface for asking natural language questions about your audio files.

---

## Tech Stack

- [AssemblyAI](https://www.assemblyai.com/) - Speech-to-text transcription.
- [LangChain](https://python.langchain.com/) - LLM orchestration and chaining.
- [Hugging Face Transformers](https://huggingface.co/) - Embedding models.
- [Chroma](https://www.trychroma.com/) - Open-source vector database.
- [OpenAI GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5) - Large language model for answering questions.
- [python-dotenv](https://pypi.org/project/python-dotenv/) - Secure API key management.

---

## Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/masinde70/Speech-To-Text-Gen-AI.git
cd Speech-To-Text-Gen-AI
```

### 2. Install Requirements

```bash
pip install -r requirements.txt
```

### 3. Set Up Environment Variables

Create a `.env` file in the project root with your API keys:
```
OPENAI_API_KEY=your_openai_api_key
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
```

### 4. Run the Application

```bash
python main.py
```

### 5. Ask Questions

- When prompted, type your question about the audio content.
- Enter `e` to exit the application.

---

## Example

```bash
$ python main.py
Transcribing files ... (may take several minutes)
Splitting documents
Embedding texts...

Enter `e` to exit
enter your question: What is Retrieval Augmented Generation?
Q: What is Retrieval Augmented Generation?
A: [Answer generated by the model]

SOURCES:
    Source 0:
        Filepath: https://storage.googleapis.com/aai-web-samples/langchain_agents_webinar.opus
        Contents: [Relevant transcript chunk...]

    ...


---

## Customization

- **Audio Files:**  
  To process your own audio, modify the `URLs` list in `main.py` with direct links to your audio files (supported formats by AssemblyAI).
- **Model Settings:**  
  You can adjust model names and parameters in the script (e.g., use a different embedding model or temperature).

---

## Notes

- All processing is performed locally except for API calls to AssemblyAI and OpenAI.
- Make sure your API keys remain private and are not committed to version control.
- This project is designed for educational and research purposes.

---

## License

This project is open source under the [MIT License](LICENSE).

---

## Acknowledgements

- Inspired by the LangChain and Chroma open-source communities.

```

Feel free to copy, edit, and replace your current README.md with this improved version! If you'd like any additional sections or have special requirements, let me know.
